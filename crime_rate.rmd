---
title: "linear R"
output:
  html_document: default
  pdf_document: default
---



```{r warning=FALSE}
library(dplyr)
crime <- read.csv("crime.csv") %>% 
dplyr::select(-X)
names(crime) <- c("percent_m", "is_south", "mean_education", "police_exp60", "police_exp59", "labour_participation", "m_per1000f", "state_pop", "nonwhites_per1000", "unemploy_m24", "unemploy_m39", "gdp", "inequality", "prob_prison", "time_prison", "crime_rate")
```

try set a linear model of crime_rate by using all of the variables, and try to identify highly correlated data in the model.


```{r warning=FALSE}
library(car)
crime_model <- lm(crime_rate ~ ., crime)
crime_exp <- lm(crime_rate ~ police_exp59 + police_exp60, crime)
vif(crime_model)
vif(crime_exp)
```

police_exp59 and police_exp60 are highly corralated, so we use feature engineering to capture both data and combine them in police_exp by finding the means.


```{r}
crime$police_exp <- (crime$police_exp59 + crime$police_exp60)/2
newcrime <- subset(crime, select=-c(police_exp59, police_exp60))
```

try to check if there're another highly correlated data.

```{r}
crime_model <- lm(crime_rate ~., newcrime)
vif(crime_model)
```
as we can see, none of the variables are highly correlated
we can check R-squared, p-value, and Significance of variables of crime_model

```{r}
summary(crime_model)
```

there're many variables that have Significance more than 0.05
we can eliminate the variables by using backward elimination, foward step-wise regression, and step-wise regression.


```{r}
step(crime_model, direction="backward")
```


```{r}
lm.start <- lm(crime_rate ~ 1, newcrime)
step(lm.start, scope=list(lower=lm.start, upper=crime_model), direction="forward")
```


```{r}
step(lm.start, scope = list(upper=crime_model), data=newcrime, direction="both")
```

after using these three methods to eliminate some of the variables, now we can compare both results to see if there're differences between these models.

```{r}
lm.back <- lm(formula = crime_rate ~ percent_m + mean_education + m_per1000f + unemploy_m24 + unemploy_m39 + inequality + prob_prison + police_exp, data = newcrime)
summary(lm.back)
```


```{r}
lm.fwdboth <- lm(formula = crime_rate ~ police_exp + inequality + mean_education + prob_prison + percent_m + unemploy_m39 + gdp, data = newcrime)
summary(lm.fwdboth)
```

if we take the variables that have Significance < 0.50 from both models(lm.back and lm.fwdboth)
we get the same result with only 6 varibles (police_exp + inequality + mean_education + 
    prob_prison + percent_m + unemploy_m39)

```{r}
lm.new <- lm(crime_rate ~ police_exp + inequality + mean_education + percent_m + prob_prison + unemploy_m39, newcrime)
summary(lm.new)
```

in this model, the R-squared and adj.R-squared value are reduced a little but the all significance of variables is lower than 0.05.
after all variables meet the requirements (R-value as close as possible to one, all the variables are significant, p-value < 0.05)
now we can try to make sure there is no more systematic pattern in this model.

```{r}
plot(newcrime$crime_rate,residuals(lm.new))
abline(h=0, lwd=2)
```

as we can see, the residual plot is randomly scattered, at this point suffice to say we can put the model(lm.new) into production as it can't be improved any further.
